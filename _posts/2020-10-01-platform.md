---
title: 'BioinfoSkills platform'
date: 2020-08-02
permalink: /posts/2020/10/platform/
tags:
  - methodology
---

## Platform

This project was conceived combining:
1. the expertise of a team of senior bioinformaticians and developers of beloved packages,
2. the excellence in cutting edge fields of applications, from microbiome analysis to outbreak monitoring,  
3. the experience of Elixir training coordinators to establish an innovative program with a long-term impact and
4. the availability of the whole team, including communications and graphic designers, to start the activities on February 2021.

Here we propose a training framework – BioinfoSkills – that:
*	Extends existing introductory courses
*	Offers self-paced training on modular bioinformatics skills that are focused on microbial genomics but can be applied and spent on several data-intensive applications
*	Embraces the opportunities of remote training with multiple media, to account for learning styles and ensure accessibility
*	Promotes networks of project-based training and hackathons, promoting code-reuse and best practices.
*	Aims at, and measures, the independence reached by the trainees
*	Complements the skill training with train-the-trainer and train-the-PI.

**A. Existing courses** — There is a particularly good amount of training material and course opportunities for absolute beginners, and we aim at building a training framework on top of them. We plan to target, primarily, all the microbiologists (and molecular biologists) that had an introductory course and would like to expand their skills and become independent users, and producers, of bioinformatics workflows. To make the content easier to browse and integrated with the whole platform we will provide “kick-off videos” to show how to make use of each resource. The “Kick-off” strategy has been already tested with R training, proving effective in motivating biologists understanding the final goal and broader context of the introductory courses.

**B. Modularity** — The aims of producing in-depth modules covering all the common problems faced by bioinformaticians, means that most of them will be also of interest to computational biologists working in fields other than microbiology or food and health. We will ensure that the modules of broad interest will be advertised in sibling communities with Twitter and Facebook campaigns, in addition to the personal involvement of key players.

**C. Remote** — Remote training, essential in case of remote working forced by the current pandemic, is also inclusive to non-academic workers and caregivers, allowing them to attend when possible and at their own pace. Pre-recorded bite-sized lessons and alternative formats are also allowing for a more customized learning path, with the possibility of elaborating on obscure areas with more examples and longer explanations when needed.

**D. Project-based** — Abstract concepts of computer science can be difficult to grasp if not paired with common applications and the benefits they can provide. When this link is not strong enough, the temptation of not implementing best practices is a broadly diffused plague that affects the quality of the bioinformatics packages available (e.g. lack of unit tests or proper software versioning).

**E. Independence** — The key long-term metric that we want to evaluate is independence in performing higher-level analyses that were not accessible before to the users. This means that from the recorded lessons to the practical workshops, an important focus will be on real-life scenarios and how to manage requirements, design and implementation of case studies.

**F. Trainers/PIs** — The nature of our training program makes it ideal to be shared and replicated in different sites and by different trainers. Each training module will be equipped with a section for trainers, and we will organize two formal “Train the trainer” events, one at the beginning of our project, targeting the trainers that will work within this project, and one at the end of the project, with the main goal of having at least three UK institutions replicating one of our modules on their site the year following the end of the project.
Bioinformatics is being widely adopted also by laboratories without prior experiences in the field. We will have a section of our “hub” dedicated to PIs (“Train the PI”), with introductory videos and resources on how to sustain their students/postdocs in training in bioinformatics, understanding that they need to secure some time regularly to be able to take the highest benefits from online training. This will greatly enhance the ability of project planning, time-management and supervision.

## Training themes

The areas of training are:

• COMPUTATIONAL SKILLS – advanced design patterns to produce a more robust analytical code. Implementing automatic tests, the programmers can monitor that updating their code will not alter previously working functionalities, and each module of their code can be independently monitored. The use of simulated datasets also ensures the ability of the analytical code to deliver the expected results when needed and using robust frameworks to project pipelines and workflows will make them more reliable, reproducible, and easier to share. The use of containers is also a rapidly emerging solution to installation and reproducibility issues, but a wide fraction of beginners is not equipped to make full use of them.

• STATISTICAL SKILLS – potentially inappropriate statistical analysis as a major contributor to irreproducible science. With 20 years of experience in training biologist to correctly use statistical methods, we will empower the researchers with the knowledge of the assumptions on which inferential tools they are based, the ability to check that these are met, and the tools to evaluate claims made by statistical package authors. For example, the near ubiquitous use of Benjamini-Hochberg corrections to p-values for multiplicity: it is our experience that very few scientists can correctly interpret the resulting “false discovery rate”, can set the appropriate threshold for this or understand the implications of the assumption that individual statistical tests are independent of each other, which is rarely met in practice.
• PHYLOGENOMICS – Phylogenetics, the study of the evolutionary relations between organisms through their genes, is treated as an afterthought in many bioinformatics courses, with input and output taken for granted. However, phylogenetic inference is in fact a branch of statistics and the evolutionary models available are very dependent on assumptions regarding the input data and the biological conditions.  
There are several tools and procedures to infer the lineage from genomics sequences, but if not used with the correct understanding of the theoretical background of phylogenomic they will produce misleading results. Phylogenetic trees are used, among the other applications, in outbreak monitoring and clinical diagnostic procedures and incorrect phylogenetic inference can lead to health risks.

• MICROBIOME ANALYSIS – The importance of bacterial communities in environmental, agricultural and biomedical sciences is growing at an unprecedented pace, together with our ability to sequence the genomes of the microbiota. Our ability to correctly analyse metagenomics datasets needs to grow, and our team includes long time metagenomics analysts and developers, to deliver the operating skills to analyse both 16S and whole metagenome sequencing with a deep insight in the confounding factors and biases that these experiments carry, and how to critically identify and mitigate them.

• MICROBIAL GENOMICS AND OUTBREAKS – The analysis of bacterial genomes is finding applications in activities affecting our wellbeing, from the analysis of clinical samples to food safety standards. Our team has been at the forefront of the genomic investigations in the current pandemic outbreak.

• NUTRITION AND BIG DATA – The Food Data Bank at the Quadram Institute is an important database with a vast amount of nutrition data, and the team behind it implements machine learning strategies to explore and exploit the high dimensional data stored. This is a perfect real-world scenario to learn how to manage and analyse a large dataset, with complex and heterogeneous information.

• VIROME ANALYSIS WORKFLOWS – Several pipelines for the analysis of metagenomics datasets have been proposed, but for viromic datasets the availability is limited, and most software is still at its infancy. Virome analysis is a great example of how to implement a robust, reproducible and shareable workflow from the ground up.
